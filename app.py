import streamlit as st
import requests

# ุฅุนุฏุงุฏ ุงูุตูุญุฉ
st.set_page_config(page_title="Chat AI", page_icon="๐ค", layout="centered")

st.title("๐ค ูุญุงุฏุซุฉ ูุน ุงูุฐูุงุก ุงูุงุตุทูุงุนู")

# ------------------------------------------------------------------
# ุฅุนุฏุงุฏุงุช ุงูุงุชุตุงู ุจุงูููุฏูู
# ------------------------------------------------------------------

# ุชู ุชุญุฏูุซ ุงูุฑุงุจุท ูู api-inference ุฅูู router ููุง ุทูุจ Hugging Face
# ุงูููุฏูู ุงูุญุงูู: Kimi-K2.5
API_URL = "https://router.huggingface.co/models/moonshotai/Kimi-K2.5"

# --- ุฎูุงุฑ ุจุฏูู (ุงุญุชูุงุทู) ---
# ุฅุฐุง ูู ูุนูู Kimi ูุฃูู ูุจูุฑ ุฌุฏุงูุ ูู ุจุญุฐู ุนูุงูุฉ # ูู ุงูุณุทุฑ ุงูุชุงูู ูุถุนูุง ุฃูุงู ุงูุณุทุฑ ุงูุณุงุจู
# API_URL = "https://router.huggingface.co/models/meta-llama/Llama-3.2-11B-Vision-Instruct"

# ุงูุชุญูู ูู ูุฌูุฏ ุงูููุชุงุญ ุงูุณุฑู ูู ุฅุนุฏุงุฏุงุช Streamlit
if 'HF_TOKEN' in st.secrets:
    headers = {"Authorization": f"Bearer {st.secrets['HF_TOKEN']}"}
else:
    st.error("โ๏ธ ูู ูุชู ุงูุนุซูุฑ ุนูู HF_TOKEN ูู ุฅุนุฏุงุฏุงุช Secrets.")
    st.stop()

def query(payload):
    try:
        response = requests.post(API_URL, headers=headers, json=payload)
        return response.json()
    except Exception as e:
        return {"error": f"Connection Error: {str(e)}"}

# ------------------------------------------------------------------
# ูุงุฌูุฉ ุงููุณุชุฎุฏู
# ------------------------------------------------------------------

# ุญูู ุฅุฏุฎุงู ุงููุต
user_input = st.text_area("ุงูุชุจ ุฑุณุงูุชู ููุง:", height=100)

# ุฒุฑ ุงูุฅุฑุณุงู
if st.button("ุฅุฑุณุงู", type="primary"):
    if not user_input.strip():
        st.warning("ุงูุฑุฌุงุก ูุชุงุจุฉ ูุต ูุจู ุงูุฅุฑุณุงู.")
    else:
        with st.spinner('ุฌุงุฑู ุงูุชูููุฑ... (ูุฏ ูุณุชุบุฑู ููุชุงู ููููุฏููุงุช ุงููุจูุฑุฉ)'):
            # ุฅุนุฏุงุฏ ุงูุจูุงูุงุช ููุฅุฑุณุงู
            # ูุฑุณู ุงููุต ููุทุ ุงูููุฏูู ุณููููู ูุณุคุงู
            payload = {
                "inputs": user_input,
                "parameters": {
                    "max_new_tokens": 250,  # ุนุฏุฏ ุงููููุงุช ูู ุงูุฑุฏ
                    "return_full_text": False 
                }
            }

            output = query(payload)

            # -------------------------------------------------------
            # ูุนุงูุฌุฉ ูุนุฑุถ ุงููุชูุฌุฉ
            # -------------------------------------------------------
            if isinstance(output, list) and len(output) > 0 and 'generated_text' in output[0]:
                st.success("ุงูุฑุฏ:")
                st.write(output[0]['generated_text'])
            
            elif isinstance(output, dict) and 'error' in output:
                st.error(f"ุญุฏุซ ุฎุทุฃ ูู ุงููุตุฏุฑ: {output['error']}")
                # ูุตูุญุฉ ูููุณุชุฎุฏู ุฅุฐุง ูุงู ุงูุฎุทุฃ ุจุณุจุจ ุญุฌู ุงูููุฏูู
                if "loading" in output['error'].lower():
                    st.info("๐ก ุงูููุฏูู ููุฏ ุงูุชุญูููุ ุญุงูู ุงูุถุบุท ุนูู ุฅุฑุณุงู ูุฑุฉ ุฃุฎุฑู ุจุนุฏ 30 ุซุงููุฉ.")
                if "too large" in output['error'].lower():
                    st.warning("๐ก ุงูููุฏูู ุงููุฎุชุงุฑ ูุจูุฑ ุฌุฏุงู ุนูู ุงูุฎุทุฉ ุงููุฌุงููุฉ. ุฌุฑุจ ุชุบููุฑ ุงูุฑุงุจุท ูู ุงูููุฏ ูุงุณุชุฎุฏุงู Llama.")
            else:
                st.write("ุฑุฏ ุบูุฑ ูุชููุน:", output)
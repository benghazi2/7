import streamlit as st
import requests
import json

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Chat AI", page_icon="ğŸ¤–")
st.title("ğŸ¤– Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")

# ------------------------------------------------------------------
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (ØªÙ… ØªØºÙŠÙŠØ± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¹Ù…Ù„)
# ------------------------------------------------------------------
# Ù†Ø³ØªØ®Ø¯Ù… Ù…ÙˆØ¯ÙŠÙ„ Zephyr Ù„Ø£Ù†Ù‡ Ø³Ø±ÙŠØ¹ Ø¬Ø¯Ø§Ù‹ ÙˆÙ…Ø¬Ø§Ù†ÙŠ ÙˆÙ…Ø®ØµØµ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
# Ø¥Ø°Ø§ Ø§Ø´ØªØºÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ù„Ø§Ø­Ù‚Ø§Ù‹ ØªØ¬Ø±Ø¨Ø© Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø£Ø®Ø±Ù‰
API_URL = "https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta"

# Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø±ÙŠ
if 'HF_TOKEN' in st.secrets:
    headers = {"Authorization": f"Bearer {st.secrets['HF_TOKEN']}"}
else:
    st.error("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ HF_TOKEN. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¶Ø¹Ù‡ ÙÙŠ Secrets.")
    st.stop()

def query(payload):
    try:
        response = requests.post(API_URL, headers=headers, json=payload)
        
        # --- ÙƒØ´Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ ---
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø¯ Ù„ÙŠØ³ 200 (Ù†Ø¬Ø§Ø­)ØŒ Ù†Ø¹Ø±Ø¶ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        if response.status_code != 200:
            return {"error": f"Status: {response.status_code}, Msg: {response.text}"}
        
        return response.json()
        
    except Exception as e:
        return {"error": f"Exception: {str(e)}"}

# ------------------------------------------------------------------
# 2. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
# ------------------------------------------------------------------

# Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Ø¹Ø´Ø§Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø§ ØªØ®ØªÙÙŠ Ù„Ù…Ø§ ØªØ¶ØºØ· Ø²Ø±)
if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Ø­Ù‚Ù„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯ (Ø£Ø³ÙÙ„ Ø§Ù„Ø´Ø§Ø´Ø© Ù…Ø«Ù„ ChatGPT)
if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§..."):
    # 1. Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø±Ø¯
    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ÙƒØªØ§Ø¨Ø©..."):
            
            # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø·Ù„Ø¨ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù†ØµÙŠ
            payload = {
                "inputs": f"<|system|>\nYou are a helpful assistant.<|user|>\n{prompt}<|assistant|>\n",
                "parameters": {"max_new_tokens": 512}
            }
            
            output = query(payload)

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯
            if isinstance(output, list) and 'generated_text' in output[0]:
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø¯ (Ù„Ø¥Ø²Ø§Ù„Ø© Ù†Øµ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ…)
                full_response = output[0]['generated_text']
                # Ù†Ø£Ø®Ø° Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ù„ÙŠ Ø¨Ø¹Ø¯ ÙƒÙ„Ù…Ø© assistant
                bot_reply = full_response.split("<|assistant|>\n")[-1]
                
                st.markdown(bot_reply)
                st.session_state.messages.append({"role": "assistant", "content": bot_reply})
            
            elif isinstance(output, dict) and 'error' in output:
                st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {output['error']}")
            else:
                st.warning(f"Ø±Ø¯ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {output}")